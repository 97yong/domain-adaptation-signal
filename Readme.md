<h1>ğŸŒ Domain-Adversarial Neural Network (DANN) for Domain Adaptation - 1D Signal</h1>

<p>
This project implements a <strong>DANN (Domain-Adversarial Neural Network)</strong> 
to perform robust fault classification under domain shift using the bearing dataset.
</p>

<hr/>

<h2>ğŸ“ Project Structure</h2>

<pre>
dann_pipeline/
â”œâ”€â”€ main.py              # Entry point (load, train, evaluate)
â”œâ”€â”€ config.py            # Argument parser
â”œâ”€â”€ dataset.py           # Source/target dataloaders
â”œâ”€â”€ model.py             # DANN architecture (feature extractor + classifiers)
â”œâ”€â”€ train.py             # Adversarial training routine
â”œâ”€â”€ test.py              # Final evaluation on target domain
â”œâ”€â”€ utils.py             # Optional tools (e.g. plotting)
â”œâ”€â”€ data/                # .npy input files
â””â”€â”€ result/              # model.pt, logs, loss curves
</pre>

<hr/>
<h2>ğŸ“¥ Dataset</h2>

<p>
This project uses two publicly available bearing fault datasets adapted for domain adaptation experiments:
</p>

<ul>
  <li>
    <strong>CWRU Bearing Dataset</strong> â€“ Provided by Case Western Reserve University<br/>
    ğŸ”— <a href="https://engineering.case.edu/bearingdatacenter/download-data-file" target="_blank">
    https://engineering.case.edu/bearingdatacenter/download-data-file
    </a>
  </li>
  <br/>
  <li>
    <strong>IMS Bearing Dataset</strong> â€“ Provided via Data.gov<br/>
    ğŸ”— <a href="https://catalog.data.gov/dataset/ims-bearings" target="_blank">
    https://catalog.data.gov/dataset/ims-bearings
    </a>
  </li>
</ul>

<p>
For signal preprocessing and conversion into <code>.npy</code> format, refer to the preprocessing code in this repository:<br/>
ğŸ”§ <a href="https://github.com/97yong/signal-fault-classification" target="_blank">
https://github.com/97yong/signal-fault-classification
</a>
</p>

<p>
Preprocessed data is saved in the following format as <code>.npy</code>:
</p>

<pre>
data/
â”œâ”€â”€ X_source.npy
â”œâ”€â”€ Y_source.npy
â”œâ”€â”€ X_target.npy
â”œâ”€â”€ Y_target.npy
â”œâ”€â”€ X_target_test.npy
â””â”€â”€ Y_target_test.npy
</pre>

<hr/>

<h2>âš™ï¸ Training Options</h2>

<p>You can configure training parameters via <code>config.py</code> or pass them through <code>opt</code>.</p>

<table>
  <tr><th>Argument</th><th>Description</th><th>Default</th></tr>
  <tr><td><code>--epochs</code></td><td>Number of training epochs</td><td>10</td></tr>
  <tr><td><code>--lr</code></td><td>Learning rate</td><td>1e-4</td></tr>
  <tr><td><code>--batch_size</code></td><td>Mini-batch size</td><td>64</td></tr>
</table>

<hr/>

<h2>ğŸ§  Model Overview</h2>

<p>
DANN consists of:
</p>
<ul>
  <li><strong>Feature Extractor</strong> â€“ 1D CNN layers</li>
  <li><strong>Label Classifier</strong> â€“ Predicts class labels for source domain</li>
  <li><strong>Domain Classifier</strong> â€“ Predicts domain (source/target) using GRL (gradient reversal)</li>
</ul>

<p>Training is done with <strong>adversarial loss</strong> to align the feature distributions.</p>

<hr/>

<h2>ğŸš€ How to Run</h2>

<pre><code>pip install numpy torch scikit-learn tqdm matplotlib</code></pre>

<pre><code>python main.py</code></pre>

<p>This will:</p>
<ol>
  <li>Load source/target domain data</li>
  <li>Train a domain-adversarial model</li>
  <li>Evaluate performance on target test data</li>
</ol>

<hr/>

<h2> Views </h2>

![](http://profile-counter.glitch.me/97yong-domain-adaptation-signal/count.svg)

<h2>ğŸ“š Reference</h2>

<p>
Ganin, Y., & Lempitsky, V. (2015). <br/>
<strong>"Unsupervised Domain Adaptation by Backpropagation."</strong> <br/>
In Proceedings of the 32nd International Conference on Machine Learning (ICML), 1180â€“1189. <br/>
ğŸ”— <a href="https://arxiv.org/abs/1409.7495" target="_blank">arXiv:1409.7495</a>
</p>

<hr/>
